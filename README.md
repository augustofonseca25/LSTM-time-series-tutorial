# Understanding Household Energy Consumption: A Deep Learning Approach <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/23/Hertie_School_of_Governance_logo.svg/1200px-Hertie_School_of_Governance_logo.svg.png" width="200px" align="right" />

This tutorial provides users with a fundamental understanding for Adversarial Machine Learning (AML), why it is dangerous, and how its risks can be mitigated. It does so by providing both mathematical and theoretical explanations as well as hands-on coding examples. Two attacks and their countermeasures are implemented, namely an evasion attack and a membership inference attack. The user will be introduced not only in the intricacies of these attacks but get an idea of their risks in general. Machine Learning systems applied in all domains can be subject to adversarial attacks, making the topic paramount to practitioners and policy-makers alike.

In addition to the tutorial itself, we also provide you with a presentation taking a more conceptual angel to introducing Adversarial Machine Learning, a video walking you through the notebook, and a link to directly open the file in Google Colab:

* [Presentation Slides]()
* [Video Guide for Tutorial Notebook]()
* [Open Tutorial in Google Colab](xxxxxxxxxxxxxxx)

**Authors:**

*   Alvaro Guijarro May [[Email](mailto:a.guijarro@students.hertie-school.org) | [GitHub]() | [LinkedIn]()]
*   Augusto Fonseca [[Email](mailto:a.fonseca@students.hertie-school.org) | [GitHub](https://github.com/augustofonseca25) | [LinkedIn](www.linkedin.com/in/augustofonseca-brazil)]
*   Luke Smith [[Email](mailto:j.halkenhaeusser@students.hertie-school.org) | [GitHub]() | [LinkedIn]()]

#<a href="XXXXXXXXXXXXXX" target="_parent">
#<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" width="200px"/></a>
